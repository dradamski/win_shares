{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose of this is to scrape winshare data from basketball-reference.com\n",
    "### THINGS TO DO NEXT ####\n",
    "# SEPARATE OUT THE WINSHARE LEADER FOR EACH WIN TOTAL\n",
    "# ADD TRENDLINE TO WS/TWIN GRAPH\n",
    "# GRAPH YEARLY LEADERS OVER TIME\n",
    "# GRAPH YEARLY LEADERS BY WS \n",
    "# HOW TO SPEED IT UP\n",
    "# HAVE LIST OF PLAYERS. FOR INSTANCE OF PLAYERS NAME, APPEND TEAM FOR A GIVEN YEAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the library used to query website\n",
    "import urllib.request\n",
    "#specify the url\n",
    "site = \"https://www.basketball-reference.com/leaders/ws_top_10.html\"\n",
    "#Query the website and return the html to the variable 'page'\n",
    "page = urllib.request.urlopen(site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drew\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Drew\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#import the Beautiful Soup functions to parse the data returned form the website\n",
    "from bs4 import BeautifulSoup\n",
    "#Parse the html in the 'page' variable and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Found data location by using print(soup.prettify()) and searching for the data.\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = soup.table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accesses table with year, player, winshares and puts info into a single list of strings.\n",
    "raw_list = []\n",
    "for string in table.stripped_strings:\n",
    "    if string != '*':    #removes hall of fame denotation\n",
    "        raw_list.append(string)\n",
    "raw_list = raw_list[13:]   #removes unneccessary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create list with years, top 10 leaders in win shares, and \n",
    "years = []\n",
    "for i in raw_list:\n",
    "    x = 0\n",
    "    if i[0]=='2' or i[0] == '1':\n",
    "        while x < 10:\n",
    "            (years.append(i))\n",
    "            x +=1\n",
    "        x=0\n",
    "\n",
    "league = []\n",
    "for i in raw_list:\n",
    "    if len(i)==3:\n",
    "        while x < 10:\n",
    "            league.append(i)\n",
    "            x += 1\n",
    "        x = 0\n",
    "\n",
    "players = []\n",
    "for player in raw_list:\n",
    "    if len(player) != 3 and player[0].isalpha():\n",
    "        players.append(player)\n",
    "\n",
    "player_links = []\n",
    "for a in table.find_all('a'):\n",
    "    if 'leagues' not in a['href']:\n",
    "        player_links.append(a['href'])\n",
    "\n",
    "win_shares = []    \n",
    "for num in raw_list:\n",
    "    if num[0] == \"(\":\n",
    "        win_shares.append(float(num[1:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drew\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Drew\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Use Beautiful Soup to find player's team for each year and then their win total.\n",
    "# Go to PLAYER page to get TEAM for YEAR -> go to YEAR's TEAM page for WINS\n",
    "\n",
    "\n",
    "site = 'https://www.basketball-reference.com/players/d/duranke01.html'\n",
    "page = urllib.request.urlopen(site)\n",
    "\n",
    "#Parse the html in the 'page' variable and store it in Beautiful Soup format\n",
    "# use year to pull team info from player page\n",
    "test_year = '2010'\n",
    "test_team = 'N/A'\n",
    "soup = BeautifulSoup(page)\n",
    "for i in soup.table.find_all('a'):\n",
    "    if (test_year in i['href']) and (i['href'][1] == 't'):\n",
    "        test_team = (i['href'][7:10])\n",
    "# use team and year to pull wins from \n",
    "site = 'https://www.basketball-reference.com/teams/%s/%s.html' % (test_team, test_year)\n",
    "page = urllib.request.urlopen(site)\n",
    "soup = BeautifulSoup(page)\n",
    "ps = (list(soup.find_all('p')))\n",
    "team_wins = int((str(ps[2]))[40:42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drew\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Drew\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 A. Davis NOP\n",
      "2019 R. Gobert UTA\n",
      "2019 J. Harden HOU\n",
      "2019 G. Antetokounmpo MIL\n",
      "2019 K. Durant GSW\n",
      "2019 C. Capela HOU\n",
      "2019 N. Jokic DEN\n",
      "2019 P. George OKC\n",
      "2019 D. Lillard POR\n",
      "2019 K. Leonard TOR\n",
      "2018 J. Harden HOU\n",
      "2018 K. Towns MIN\n",
      "2018 L. James CLE\n",
      "2018 A. Davis NOP\n",
      "2018 D. Lillard POR\n",
      "2018 G. Antetokounmpo MIL\n",
      "2018 L. Aldridge SAS\n",
      "2018 N. Jokic DEN\n",
      "2018 K. Durant GSW\n",
      "2018 A. Drummond DET\n",
      "2017 J. Harden HOU\n",
      "2017 R. Gobert UTA\n",
      "2017 J. Butler CHI\n",
      "2017 K. Leonard SAS\n",
      "2017 R. Westbrook OKC\n",
      "2017 L. James CLE\n",
      "2017 K. Towns MIN\n",
      "2017 S. Curry GSW\n",
      "2017 I. Thomas BOS\n",
      "2017 G. Antetokounmpo MIL\n",
      "2016 S. Curry GSW\n",
      "2016 K. Durant OKC\n",
      "2016 R. Westbrook OKC\n",
      "2016 K. Leonard SAS\n",
      "2016 L. James CLE\n",
      "2016 J. Harden HOU\n",
      "2016 C. Paul LAC\n",
      "2016 K. Lowry TOR\n",
      "2016 D. Jordan LAC\n",
      "2016 D. Green GSW\n",
      "2015 J. Harden HOU\n",
      "2015 C. Paul LAC\n",
      "2015 S. Curry GSW\n",
      "2015 A. Davis NOP\n",
      "2015 D. Jordan LAC\n",
      "2015 J. Butler CHI\n",
      "2015 R. Westbrook OKC\n",
      "2015 D. Lillard POR\n",
      "2015 P. Gasol CHI\n",
      "2015 K. Irving CLE\n",
      "2014 K. Durant OKC\n",
      "2014 L. James MIA\n",
      "2014 K. Love MIN\n",
      "2014 S. Curry GSW\n",
      "2014 J. Harden HOU\n",
      "2014 B. Griffin LAC\n",
      "2014 C. Paul LAC\n",
      "2014 K. Lowry TOR\n",
      "2014 J. Noah CHI\n",
      "2014 D. Jordan LAC\n",
      "2013 L. James MIA\n",
      "2013 K. Durant OKC\n",
      "2013 C. Paul LAC\n",
      "2013 J. Harden HOU\n",
      "2013 R. Westbrook OKC\n",
      "2013 M. Gasol MEM\n",
      "2013 S. Curry GSW\n",
      "2013 K. Bryant LAL\n",
      "2013 D. Williams BRK\n",
      "2013 B. Griffin LAC\n",
      "2012 L. James MIA\n",
      "2012 C. Paul LAC\n",
      "2012 K. Durant OKC\n",
      "2012 K. Love MIN\n",
      "2012 T. Chandler NYK\n",
      "2012 J. Harden OKC\n",
      "2012 B. Griffin LAC\n",
      "2012 J. Noah CHI\n",
      "2012 R. Anderson ORL\n",
      "2012 P. Gasol LAL\n",
      "2011 L. James MIA\n",
      "2011 P. Gasol LAL\n",
      "2011 D. Howard ORL\n",
      "2011 C. Paul NOH\n",
      "2011 D. Rose CHI\n",
      "2011 D. Wade MIA\n",
      "2011 K. Durant OKC\n",
      "2011 P. Pierce BOS\n",
      "2011 K. Love MIN\n",
      "2011 D. Nowitzki DAL\n",
      "2010 L. James CLE\n",
      "2010 K. Durant OKC\n",
      "2010 D. Howard ORL\n",
      "2010 D. Wade MIA\n",
      "2010 D. Nowitzki DAL\n",
      "2010 G. Wallace CHA\n",
      "2010 P. Gasol LAL\n",
      "2010 T. Duncan SAS\n",
      "2010 A. Horford ATL\n",
      "2010 N. Hilario DEN\n",
      "2009 L. James CLE\n",
      "2009 C. Paul NOH\n",
      "2009 D. Wade MIA\n",
      "2009 P. Gasol LAL\n",
      "2009 D. Howard ORL\n",
      "2009 B. Roy POR\n",
      "2009 K. Bryant LAL\n",
      "2009 R. Allen BOS\n",
      "2009 D. Nowitzki DAL\n",
      "2009 Y. Ming HOU\n",
      "2008 C. Paul NOH\n",
      "2008 L. James CLE\n",
      "2008 A. Stoudemire PHO\n",
      "2008 K. Bryant LAL\n",
      "2008 C. Billups DET\n",
      "2008 D. Howard ORL\n",
      "2008 D. Nowitzki DAL\n",
      "2008 K. Garnett BOS\n",
      "2008 P. Pierce BOS\n",
      "2008 A. Iverson DEN\n",
      "2007 D. Nowitzki DAL\n",
      "2007 L. James CLE\n",
      "2007 T. Duncan SAS\n",
      "2007 K. Bryant LAL\n",
      "2007 S. Nash PHO\n",
      "2007 S. Marion PHO\n",
      "2007 E. Brand LAC\n",
      "2007 C. Billups DET\n",
      "2007 L. Deng CHI\n",
      "2007 A. Stoudemire PHO\n",
      "2006 D. Nowitzki DAL\n",
      "2006 L. James CLE\n",
      "2006 C. Billups DET\n",
      "2006 K. Bryant LAL\n",
      "2006 K. Garnett MIN\n",
      "2006 E. Brand LAC\n",
      "2006 S. Marion PHO\n",
      "2006 D. Wade MIA\n",
      "2006 G. Arenas WAS\n",
      "2006 S. Nash PHO\n",
      "2005 K. Garnett MIN\n",
      "2005 D. Nowitzki DAL\n",
      "2005 A. Stoudemire PHO\n",
      "2005 L. James CLE\n",
      "2005 S. Marion PHO\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e360d6f53a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.basketball-reference.com/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfx_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfx_year\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m't'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m        \u001b[1;31m# It's a file-type object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mmarkup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         elif len(markup) <= 256 and (\n\u001b[1;32m    193\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34mb'<'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Drew\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use Beautiful Soup to find player's team for each year and then their win total.\n",
    "# Go to PLAYER page to get TEAM for YEAR -> go to YEAR's TEAM page for WINS\n",
    "# CREATE SITE TO PULL TEAM WINS FROM\n",
    "teams = []\n",
    "# use year to pull team info from player page\n",
    "for i in range(820):\n",
    "    fx_player = players[i]\n",
    "    fx_link = player_links[i]\n",
    "    if years[i][:2] + years[i][-2:] == '1900':\n",
    "        fx_year = '2000'\n",
    "    else:\n",
    "        fx_year = years[i][:2] + years[i][-2:]\n",
    "    fx_league = league[i]\n",
    "    site = 'https://www.basketball-reference.com/%s' % (fx_link)\n",
    "    page = urllib.request.urlopen(site)\n",
    "    soup = BeautifulSoup(page)\n",
    "    for j in soup.table.find_all('a'):\n",
    "        if (fx_year in j['href']) and (j['href'][1] == 't'):\n",
    "            fx_team = (j['href'][7:10])\n",
    "            teams.append(fx_team)\n",
    "            break\n",
    "    print(fx_year, fx_player, fx_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use team and year to pull wins from\n",
    "team_wins = []\n",
    "\n",
    "for k in range(820):\n",
    "    fx_team = teams[k]\n",
    "    if years[k][:2] + years[k][-2:] == '1900':\n",
    "        fx_year = '2000'\n",
    "    else:\n",
    "        fx_year = years[k][:2] + years[k][-2:]\n",
    "    site = 'https://www.basketball-reference.com/teams/%s/%s.html' % (fx_team, fx_year)\n",
    "    page = urllib.request.urlopen(site)\n",
    "    soup = BeautifulSoup(page)\n",
    "    paragraphs = (list(soup.find_all('p')))\n",
    "    fx_wins = int((str(paragraphs[2]))[40:42])\n",
    "    team_wins.append(fx_wins)\n",
    "    print(players[k], years[k], teams[k], fx_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(teams), len(team_wins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataframe to perform analysis on\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Year':years,\n",
    "                   'League':league,\n",
    "                   'Player':players,\n",
    "                    'Win shares':win_shares,\n",
    "                   'Link':href,\n",
    "                   'Team':teams,\n",
    "                   'Team Wins':team_wins})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(team_wins, win_shares)\n",
    "plt.ylabel('Win Shares')\n",
    "plt.xlabel('Team Wins')\n",
    "plt.title('Comparison Between Team Wins and Wins for Top Ten Season Leaders (1947-2019)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# look at frequency \n",
    "leaders = {}\n",
    "for name in list(df[\"Player\"]):\n",
    "    if name not in leaders:\n",
    "        leaders[name] = 1\n",
    "    else:\n",
    "        leaders[name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = []\n",
    "values = []\n",
    "for key in leaders.keys():\n",
    "    if leaders[key] > 5:\n",
    "        keys.append(key)\n",
    "        values.append(leaders[key])\n",
    "\n",
    "leader_df = pd.DataFrame({'Name': keys,\n",
    "                         'Frequency':values})\n",
    "leader_df.sort_values(by = ['Frequency'], ascending =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('ws.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execut('''CREATE TABLE winshares ()''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
